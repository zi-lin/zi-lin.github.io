---
title: "Semantic Parsing"
hidden: true
last_modified_at: 2018-11-26
tag: NLP Tasks
author: Zi Lin
date: 2018-11-11
---
# Introduction
In fact, "semantic parsing" is, ironically, a semantically ambiguous term, which could refer to:

- Semantic role labeling (also known as shallow semantic parsing, see previous post for more information).
- Finding generic relations in text.
- Transforming a natrual language sentence into its meaning representation.

In this post, semantic parsing is the task of mapping natrual language sentences (NL) into complete **formal meaning representation** (MRs) which a computer can execute for some domain -specific application [^1]. Representing the meaning of natural language is ultimately a difficult philosophical question and many attempts have been made to define generic formal semantics of natural language, including:

- **Meaning Representation Language (MRL):** MRL is designed by the creator of the application to suit the application's needs independent of natural language. Some MRL data sets are based on Prolog database.

- **SQL Query**

- **Abstract Meaning Representation (AMR)**

- **Minimal Recursion Semantics (MRS)**

- **Semantic Dependency Parsing (SDP)**

# Abstract Meaning Representation

Abstract Meaning Representation (AMR) [^2] is a semantic formalism in which the meaning of a sentence is encoded as a rooted, directed, acyclic graph. Nodes represent concepts, and labeled directed graph edges represent the relationships between them. For example, for the sentence "the boy wants to believe the girl" we can have the corresponding AMR graph (in penman format) as:

```
(w / want-01
	:ARG0 (b / boy)
	:ARG1 (b2 / believe-01
		:ARG0 (g / girl)
		:ARG1 b))
```

AMR parsing, the task of transforming a sentence into its AMR graph, is a challenging task as it requires the parser to learn to predict not only concepts, which consist of **predicates**, **lemmas**, **named entites**, **wiki-links** and **co-references**, but also a large number of **relation types** based on the semantic role in PropBank (see the previous blog [Semantic Role Labeling](../SRL/) if you are interested).

## Data
There are multiple version of AMR data, including:
- **LDC2013E117:** 10,853 sentences with 13,050 AMRs (corpus includes multiple annotations for some sentences)
- **[LDC2014T12](https://catalog.ldc.upenn.edu/LDC2014T12) (AMR 1.0):** 13,051 sentences.
- **LDC2015E86:** 19,572 sentences. This version includes more AMRs, wikification, AMR adoption of new unfied PropBank frames, AMR deepening, automatic AMR-English alignments, and correction of AMR annotation errors.
- **LDC2016E25:** 39,260 sentences.
- **[LDC2017T10](https://catalog.ldc.upenn.edu/LDC2017T10) (AMR 2.0):** 39,260 sentences.

## Experiment

These are the AMR parsing results on LDC2014T12, LDC2015E86 and LDC2017T10 test sets, where 2014N refers to the newswire section of LDC2014T12. You should look the original paper if you are intersted in the model. **Please contact me (through email) if the statistics is incorrect.**

| Paper | Model | LDC2014N | LDC2014 | LDC2015 | LDC2017 |
|:-----:|:-----:|:--------:|:-------:|:-------:|:-------:|
|[ACL-18](http://aclweb.org/anthology/P18-1037) | Lyu & Titov<br>*University of Edinburgh & University of Amsterdam* | - | - | **73.7** | **74.4** |
|[ACL-18](http://aclweb.org/anthology/P18-1170) | Groschwitz et al.<br>*Saarland University & Macquerie University* | - | - | 70.2 | 71.0 |
|[ACL-17](http://www.aclweb.org/anthology/P17-1112.pdf) | Buys & Blunsom<br>*University of Oxford & Deepmind* | - | - | - | 61.9 |
|[ACL-17](http://www.aclweb.org/anthology/P17-1043) | Foland & Martin<br>*University of Colorado* | - | - | 70.7 | - |
|[EMNLP-18](http://aclweb.org/anthology/D18-1198) | Guo & Lu<br>*Singapore University of Technology & Design* | **74.0** | **68.3** | 68.7 | 69.8 |
|[Arxiv-17](https://arxiv.org/abs/1705.09980) | van Noord & Bos<br>*University of Groningen* | - | - | 68.5 | 71.0 | 
|[EMNLP-17](http://aclweb.org/anthology/D17-1129) | Wang & Xue<br>*Brandeis University* | - | 68.1 | 68.1 | - |
|[Semeval-16](http://www.aclweb.org/anthology/S16-1181) | Wang et al. (CAMR)<br>*Brandeis University & Boulder Language Technologies* | - | 66.5 | 67.3 | - |
|[Semeval-16](http://www.aclweb.org/anthology/S16-1176) | Barzdins & Gosko<br>*University of Latvia* | - | - | 67.2 | - |
|[Semeval-16](http://aclweb.org/anthology/S16-1186) | Flanigan et al. (JAMR)<br>*Carnegie Mellon University & University of Washington* | -  | 66 | 67 | - |
|[EACL-17](http://www.aclweb.org/anthology/E17-1051) | Damonte et al.<br>*University of Edinburgh & University of Padua* | - | 64 | 64 | - |
|[NAACL-18](http://aclweb.org/anthology/N18-2023) | Vilares & Gómez-Rodríguez<br>*Universidade da Coruña* | - | - | 64 | - |
|[AAAI-18](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16563/16021) | Peng et al.<br>*University of Rochester & University of Padua* | - | - | 64 | - |
|[ACL-17](http://aclweb.org/anthology/P17-1014) | Konstas et al.<br>*University of Washington & Allen Institute for Artificial Intelligence* | - | - | 62.1 | - |
|[EACL-17](http://aclweb.org/anthology/E17-1035) | Peng et al.<br>*University of Rochester & Brandeis University* | - | - | 52 | - |
|[EMNLP-15](http://www.aclweb.org/anthology/D15-1136) | Pust et al.<br>*Univerisity of Southern California* | - | 67.1 | - | - |
|[EMNLP-16](http://aclweb.org/anthology/D16-1065) | Zhou et al.<br>*Nianjin Normal University & DFKI, Germany* | 71 | 66 | - | - |
|[Semeval-16](http://www.aclweb.org/anthology/S16-1180) | Goodman et al.<br>*University College London & University of Sheffeld* | 70 | - | 64 | - |
|[ACL-IJCNLP-15](http://www.aclweb.org/anthology/P15-2141.pdf) | Wang et al. (CAMR)<br>*Brandeis University & Boulder Language Technologies* | 70 | 66 | - | - |
|[EMNLP-17](http://aclweb.org/anthology/D17-1130) | Ballesteros & AI-Onaizan<br>*IBM T.J Waston Research Center* | 69 | 64 | - | - |
|[EMNLP-15](http://www.aclweb.org/anthology/D15-1198) | Artzi et al.<br>*Cornell University & University of Washington* | 67 | - | - | - |
|[ACL-IJCNLP-15](http://aclweb.org/anthology/P15-1095) | Werling et al.<br>*Stanford University* | 62 | - | - | - |
|[NAACL-15](http://www.aclweb.org/anthology/N15-1040) | Wang et al. (CAMR)<br>*Brandeis University & Harvard Medical School* | - | 59 | - | - |
|[ACL-14](http://aclweb.org/anthology/P14-1134) | Flanigan et al. (JAMR)<br>*Carnegie Mellon University* | 59 | 58 | - | - |
|[CoNLL-15](https://www.aclweb.org/anthology/K15-1004) | Peng et al.<br>*University of Rochester* | 58 | - | - | - |

# Semantic Dependency Parsing

Task 8 at SemEval 2014 defines *Broad-Coverage Semantic Dependency Parsing* (SDP) as the problem of recovering sentence-internal predicate-argument relationships for *all content words*, i.e., the semantic structure constituting the relational core of sentence meaning[^3].

SDP seeks to stimulate the dependency parsing community to move towards more general graph processing, to thus enable a more direct analysis of *Who did What to Whom?* In additon to its relation to syntactic dependency parsing, the task also has some overlap with Semantic Role Labeling (SRL)[^4].

The SDP parsers are required to identify all semantic dependencies, i.e., compute a representation that integrates all content words in one structure. Different from SRL, SDP task does not encompass predicate disambiguation, a design decision in part owed to SDP's goal to focus on parsing-oriented, i.e., structural, analysis, and in part to lacking consensus on sense inventories for all content words.

SDP uses three distinct targer representations for semantic dependencies. Including:

## DM: DELPH-IN MRS-Derived Bi-Lexical Dependencies

These semantic dependency graphs originate in a manual re-annotation of Sections 00–21 of the WSJ Corpus with syntactico-semantic analyses derived from the LinGO English Resource Grammar (ERG)[^5]. The DM targer representations are derived through a two-step 'lossy' conversion of MRSs, first to variable-free Elementary Dependency Structures (EDS)[^6], then to 'pure' bi-lexical form - projecting some construction semantics onto word-to-word dependencies[^7]. For example, for the sentence "Ms. Haag plays Elianti.", we have the DM representation as follows:

| id | form | lemma | pos | top | pred | arg1 | arg2 |
|:--:|:----:|:-----:|:---:|:---:|:----:|:----:|:----:|
| 1 | Ms. | Ms. | NNP | - | + | \_ | \_ |
| 2 | Haag| Haag| NNP | - | - | compound | ARG1|
| 3 | plays|play| VBZ | + | + | \_ | \_ |
| 4 |Elianti|Elianti|NNP|-| - | \_ | ARG2|
| 5 | .     | . | . |-| - | \_ | \_ |

[^1]: Rohit J Kate and YukWahWong. 2010. Semantic parsing: The task, the state of the art and the future. Tutorial Abstracts of ACL 2010 page 6.
[^2]: Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider. 2013. Abstract meaning representation for SemBanking. In Proc. of the 7th Linguistic Annotation Workshop and Interoperability with Discourse.


















