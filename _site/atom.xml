<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-05-01T20:05:31+08:00</updated><id>http://localhost:4000/</id><title type="html">Zi Lin</title><subtitle>[firstname].[lastname]@pku.edu.cn</subtitle><author><name>Zi Lin</name><email>linzi.pku@gmail.com</email></author><entry><title type="html">Domain Adaptation for Syntactic Analysis</title><link href="http://localhost:4000/domain-adaptation/" rel="alternate" type="text/html" title="Domain Adaptation for Syntactic Analysis" /><published>2019-05-01T00:00:00+08:00</published><updated>2019-05-01T00:00:00+08:00</updated><id>http://localhost:4000/domain-adaptation</id><content type="html" xml:base="http://localhost:4000/domain-adaptation/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Current NLP systems tend to perform well only on their training domain and nearby genres, while the performances often degrade on the data drawn from different domains.&lt;/p&gt;

&lt;p&gt;Recently, many endeavors have been made to explore and solve the problems of domain adaptation, ranging from creating challenging datasets to building algorithm that can avoid overfitting on the training data or transfer to the new domains. Here we will discuss several datasets build for the out-of-domain NLP task of syntactic analysis as well as some ideas on how to address the problem of domain adaptation. Note that in the literature, many definitions of the source domain and the target domain are proposed, here domain adaptation refers to the domains within the same NLP task and language (mainly English), but for other genres and domains such as emails, web forums and biomedical papers in terms of the dominant source domain of the Penn Treebank of Wall Street Journal (WSJ, financial news).&lt;/p&gt;

&lt;h1 id=&quot;datasets&quot;&gt;Datasets&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://catalog.ldc.upenn.edu/LDC2009T26&quot;&gt;Brown, ATIS &amp;amp; Switchboard of Treebank-3&lt;/a&gt;&lt;/strong&gt;: The Treebank-3 released by LDC also contains different domains other than WSJ: (1) the Brown Corpus (domain of literature), which has been completely retagged using the Penn Treebank tag set; (2) ATIS, the data from Department of Energy abstracts; (3) Switchboard, a collection of spontaneous telephone conversations between previously unacquainted speakers of American English on a variety of topics chosen from a pre-determined list.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://catalog.ldc.upenn.edu/LDC2012T13&quot;&gt;English Web Treebank (EWT)&lt;/a&gt;&lt;/strong&gt;: English Web Treebank was developed by the Linguistic Data Consortium (LDC) with funding from Google Inc. It contains 254,830 word-level tokens and 16,624 sentence-level tokens of webtext in 1174 files annotated for sentence- and word-level &lt;strong&gt;tokenization,&lt;/strong&gt; &lt;strong&gt;part-of-speech&lt;/strong&gt;, and &lt;strong&gt;syntactic structure&lt;/strong&gt;. The data is roughly evenly divided across five genres: weblogs, newsgroups, email, reviews, and question-answers. The files were manually annotated following the sentence-level tokenization guidelines for web text and the word-level tokenization guidelines developed for English treebanks.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/Oneplus/Tweebank&quot;&gt;Tweebank&lt;/a&gt;&lt;/strong&gt;: Tweebank v2 is a collection of English tweets annotated in &lt;strong&gt;Universal Dependencies&lt;/strong&gt; that can be exploited for the training of NLP systems to enhance their performance on social media texts. It is built on the original data of Tweebank v1 (840 unique tweets, 639/201 for training/test set), along with an additional 210 tweets sampled from the &lt;strong&gt;POS-tagged&lt;/strong&gt; dataset of Gimpel et al. (2011) &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; and 2,500 tweets sampled from the Twitter stream from Feb. 2016 to Jul. 2016. The latter data source consists of 147.4M English tweets. In the same way as Kong et al. (2011)&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, reference unit is always the tweet in its entirety – which may thus consist of multiple sentences – not the sentence alone.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://catalog.ldc.upenn.edu/LDC2012T02&quot;&gt;English Translation Treebank (ETT)&lt;/a&gt;&lt;/strong&gt;: English Translation Treebank consists of 599 distinct newswire stories from the Lebanese publication An Nahar translated from Arabic to English and annotated for &lt;strong&gt;part-of-speech&lt;/strong&gt; and &lt;strong&gt;syntactic structure&lt;/strong&gt;. This corpus is part of an effort at LDC to produce parallel Arabic and English treebanks.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://catalog.ldc.upenn.edu/LDC2008T21&quot;&gt;PennBioIE Oncology&lt;/a&gt;&lt;/strong&gt;: The PennBioIE Oncology Corpus consists of 1414 &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/entrez/query.fcgi&quot;&gt;PubMed&lt;/a&gt; abstracts on cancer, concentrating on molecular genetics, and comprising approximately 327,000 words of biomedical text, tokenized and annotated for paragraph, sentence, &lt;strong&gt;part of speech&lt;/strong&gt;, and 24 types of &lt;strong&gt;biomedical named entities&lt;/strong&gt; in five categories of interest. 318 of the abstracts have also been &lt;strong&gt;syntactically&lt;/strong&gt; annotated. All of the annotation was based on &lt;a href=&quot;http://www.cis.upenn.edu/~treebank/&quot;&gt;Penn Treebank II&lt;/a&gt; standards, with some modifications for special characteristics of the biomedical text.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://www.geniaproject.org/genia-corpus&quot;&gt;GENIA corpus&lt;/a&gt;&lt;/strong&gt;: The corpus contains 1,999 Medline abstracts, selected using a &lt;a href=&quot;http://pubmed.com/&quot;&gt;PubMed&lt;/a&gt; query for the three MeSH terms “human”, “blood cells”, and “transcription factors”. The corpus has been annotated with various levels of linguistic and semantic information, including: &lt;strong&gt;part-of-speech annotation&lt;/strong&gt;, &lt;strong&gt;constituency syntactic annotation&lt;/strong&gt;, term annotation, event annotation, relation annotation, and &lt;strong&gt;coreference annotation&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Dataset&lt;/th&gt;
      &lt;th&gt;Style&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;POS&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;NER&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Coref&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;#Token&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Brown&lt;/td&gt;
      &lt;td&gt;PTB&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;✔&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;486,140&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ATIS&lt;/td&gt;
      &lt;td&gt;PTB&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;✔&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Switchboard&lt;/td&gt;
      &lt;td&gt;PTB&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;✔&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;EWT&lt;/td&gt;
      &lt;td&gt;PTB&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;✔&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;254,830&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Tweebank&lt;/td&gt;
      &lt;td&gt;UD&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;✔&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;55,427&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ETT&lt;/td&gt;
      &lt;td&gt;PTB&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;✔&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;461,489&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PennBio&lt;/td&gt;
      &lt;td&gt;PTB&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;✔&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;✔&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;327,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GENIA&lt;/td&gt;
      &lt;td&gt;PTB&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;✔&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;✔&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;468,793&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proc. of ACL. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Lingpeng Kong, Nathan Schneider, Swabha Swayamdipta, Archna Bhatia, Chris Dyer, and Noah A. Smith. 2014. A Dependency Parser for Tweets. In Proc. of EMNLP. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Zi Lin</name></author><category term="NLP Tasks" /><summary type="html">Introduction Current NLP systems tend to perform well only on their training domain and nearby genres, while the performances often degrade on the data drawn from different domains.</summary></entry><entry><title type="html">Constituent-to-dependency Conversion</title><link href="http://localhost:4000/constituent-to-dependency/" rel="alternate" type="text/html" title="Constituent-to-dependency Conversion" /><published>2019-04-29T00:00:00+08:00</published><updated>2019-04-29T00:00:00+08:00</updated><id>http://localhost:4000/constituent-to-dependency</id><content type="html" xml:base="http://localhost:4000/constituent-to-dependency/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Since dependency structure is not constrained by word order, it is considered to be more domain or language independent than phrase structure. Most current state-of-the-art dependency parsers use a supervised learning approach, which usually requires a large amount of annotated data. For English, there are some manually annotated dependency Treebanks available &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. Nonetheless, constituent-based Treebanks such as Penn Treebank are more dominant. Therefore, it is quite natural to built the tools that convert phrase structure to dependency structure.&lt;/p&gt;

&lt;h1 id=&quot;tools&quot;&gt;Tools&lt;/h1&gt;
&lt;p&gt;There have been several tools that convert constituent structures to dependency structures. Let’s assume that the constituency tree is in the Penn Treebank style as:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;../images/constituent.png&quot; alt=&quot;drawing&quot; width=&quot;600px&quot; /&gt;
&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://cl.lingfil.uu.se/~nivre/research/Penn2Malt.html&quot;&gt;Penn2Malt&lt;/a&gt;&lt;/strong&gt; &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;: it adds semantic dependencies extracted from function tags in the Penn Treebank (e.g., &lt;code class=&quot;highlighter-rouge&quot;&gt;LOC&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;TMP&lt;/code&gt;) and remaps dependencies related to empty categories, producing non-projective dependencies.&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;../images/malt.png&quot; alt=&quot;drawing&quot; width=&quot;600px&quot; /&gt;
&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;http://nlp.cs.lth.se/software/treebank_converter/&quot;&gt;LTH&lt;/a&gt;&lt;/strong&gt; &lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;: it makes use of the extended structure of the new version of the Penn Treebank to derive a more ‘‘semantically useful’’ representation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;../images/lth.png&quot; alt=&quot;drawing&quot; width=&quot;600px&quot; /&gt;
&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/clir/clearnlp-guidelines/blob/master/md/components/dependency_conversion.md&quot;&gt;ClearNLP&lt;/a&gt;&lt;/strong&gt; &lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;:it generates the Emory style dependency trees as output, where the dependency labels are similar to the &lt;a href=&quot;https://nlp.stanford.edu/software/stanford-dependencies.shtml&quot;&gt;Stanford dependency labels&lt;/a&gt;, producing long-distance dependencies by remapping empty categories in constituent trees, and secondary dependencies caused by several linguistic phenomena. For more details about the conversion labels, see &lt;a href=&quot;http://www.mathcs.emory.edu/~choi/doc/cu-2012-choi.pdf&quot;&gt;the guideline&lt;/a&gt; for reference.&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;../images/clear.png&quot; alt=&quot;drawing&quot; width=&quot;600px&quot; /&gt;
&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://nlp.stanford.edu/software/stanford-dependencies.shtml&quot;&gt;Stanford Dependencies&lt;/a&gt;&lt;/strong&gt; &lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;: The Stanford Dependency converter was first introduced in &lt;em&gt;de Marneffe et al. (2006)&lt;/em&gt;&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; and then updated according to the &lt;a href=&quot;https://universaldependencies.org/en/index.html&quot;&gt;English Universal Dependencies&lt;/a&gt; guidelines. Since version 3.5.2 the Stanford Parser and Stanford CoreNLP output grammatical relations in the Universal Dependencies v1 representation by default. They also revisited and extended the dependency graph representations in light of the recent Universal Dependencies initiative and provide a detailed account of an &lt;em&gt;enhanced&lt;/em&gt; and an &lt;em&gt;enhanced++&lt;/em&gt; English UD representation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;../images/stanford.png&quot; alt=&quot;drawing&quot; width=&quot;600px&quot; /&gt;
&lt;/p&gt;

&lt;h1 id=&quot;issues-when-converting-to-ud&quot;&gt;Issues when converting to UD&lt;/h1&gt;
&lt;p&gt;Most of the relations in the Universal Dependencies can be added with syntactic rules. The purely syntactic approach introduced in &lt;em&gt;Schuster and Manning (2016)&lt;/em&gt; tends to work well in practice but two phenomena require additional consideration, and thus raise some uncertainty during the conversion.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Multi-word Expression&lt;/strong&gt;: the UD representation defines several multi-word expressions with function words that behave like a single word such as &lt;em&gt;because of&lt;/em&gt; or &lt;em&gt;in case&lt;/em&gt;. Extracting the correct structure for these expressions is often challenging because many of these expressions are not a constituent according to the Penn Treebank annotation guidelines &lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;wh-words&lt;/strong&gt;: the procedure often attaches wh-words in questions in the wrong head. For example, for the question “What does Peter seem to have?”, the procedure would attach “what” to the head of the matrix clause, “seem”, instead of the head of the embedded clause, “have”. If we were only concerned with converting manually annotated treebanks, we could resolve these ambiguities by making use of the indexed empty nodes in the phrase structure trees. However, the output of most constituency
parsers does not contain these empty nodes.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Owen Rambow, Cassandre Creswell, Rachel Szekely, Harriet Taber, and Marilyn Walker. A dependency treebank for english. In Proceedings of LREC’02, 2002. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;M. Cmejrek, J. Curín, and J. Havelka. Prague czech-english dependency treebank: Any hopes for a common annotation scheme? In HLT-NAACL’04 workshop on Frontiers in Corpus Annotation, pages 47–54, 2004. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;Joakim Nivre, Johan Hall, and Jens Nilsson. 2006. MaltParser: A data-driven parser generator for dependency parsing. In Proceedings of LREC2006. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Johansson, R., &amp;amp; Nugues, P. 2007. Extended constituent-to-dependency conversion for English. In &lt;em&gt;Proceedings of the 16th Nordic Conference of Computational Linguistics (NODALIDA 2007)&lt;/em&gt; (pp. 105-112). &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;Choi, J. D., &amp;amp; Palmer, M. 2010. Robust constituent-to-dependency conversion for English. In &lt;em&gt;Proceedings of the 9th International Workshop on Treebanks and Linguistic Theories (TLT’9)&lt;/em&gt; (pp. 55-66). &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;Schuster, S., &amp;amp; Manning, C. D. 2016. Enhanced English Universal Dependencies: An Improved Representation for Natural Language Understanding Tasks. In LREC (pp. 23-28). &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;de Marneffe, M.-C., MacCartney, B., and Manning, C. D. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC-2006). &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;Marcus, M. P., Santorini, B., and Marcinkiewicz, M. A. 1993. Building a large annotated corpus of English: The Penn treebank. Computational Linguistics, 19(2). &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Zi Lin</name></author><category term="NLP Tasks" /><summary type="html">Introduction Since dependency structure is not constrained by word order, it is considered to be more domain or language independent than phrase structure. Most current state-of-the-art dependency parsers use a supervised learning approach, which usually requires a large amount of annotated data. For English, there are some manually annotated dependency Treebanks available 12. Nonetheless, constituent-based Treebanks such as Penn Treebank are more dominant. Therefore, it is quite natural to built the tools that convert phrase structure to dependency structure. Owen Rambow, Cassandre Creswell, Rachel Szekely, Harriet Taber, and Marilyn Walker. A dependency treebank for english. In Proceedings of LREC’02, 2002. &amp;#8617; M. Cmejrek, J. Curín, and J. Havelka. Prague czech-english dependency treebank: Any hopes for a common annotation scheme? In HLT-NAACL’04 workshop on Frontiers in Corpus Annotation, pages 47–54, 2004. &amp;#8617;</summary></entry><entry><title type="html">Semantic Parsing</title><link href="http://localhost:4000/SP/" rel="alternate" type="text/html" title="Semantic Parsing" /><published>2018-11-11T00:00:00+08:00</published><updated>2018-11-26T00:00:00+08:00</updated><id>http://localhost:4000/SP</id><content type="html" xml:base="http://localhost:4000/SP/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In fact, “semantic parsing” is, ironically, a semantically ambiguous term, which could refer to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Semantic role labeling (also known as shallow semantic parsing, see previous post for more information).&lt;/li&gt;
  &lt;li&gt;Finding generic relations in text.&lt;/li&gt;
  &lt;li&gt;Transforming a natural language sentence into its meaning representation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this post, semantic parsing is the task of mapping natural language sentences (NL) into complete &lt;strong&gt;formal meaning representation&lt;/strong&gt; (MRs) which a computer can execute for some domain -specific application &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Representing the meaning of natural language is ultimately a difficult philosophical question and many attempts have been made to define generic formal semantics of natural language, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Abstract Meaning Representation (AMR)&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Semantic Dependency Parsing (SDP)&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Meaning Representation Language (MRL)&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;SQL Query&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;abstract-meaning-representation&quot;&gt;Abstract Meaning Representation&lt;/h1&gt;

&lt;p&gt;Abstract Meaning Representation (AMR) &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; is a semantic formalism in which the meaning of a sentence is encoded as a rooted, directed, acyclic graph. Nodes represent concepts, and labeled directed graph edges represent the relationships between them. For example, for the sentence “the boy wants to believe the girl” we can have the corresponding AMR graph (in penman format) as:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(w / want-01
	:ARG0 (b / boy)
	:ARG1 (b2 / believe-01
		:ARG0 (g / girl)
		:ARG1 b))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;AMR parsing, the task of transforming a sentence into its AMR graph, is a challenging task as it requires the parser to learn to predict not only concepts, which consist of &lt;strong&gt;predicates&lt;/strong&gt;, &lt;strong&gt;lemmas&lt;/strong&gt;, &lt;strong&gt;named entities&lt;/strong&gt;, &lt;strong&gt;wiki-links&lt;/strong&gt; and &lt;strong&gt;co-references&lt;/strong&gt;, but also a large number of &lt;strong&gt;relation types&lt;/strong&gt; based on the semantic role in PropBank (see the previous blog &lt;a href=&quot;../SRL/&quot;&gt;Semantic Role Labeling&lt;/a&gt; if you are interested).&lt;/p&gt;

&lt;h2 id=&quot;data&quot;&gt;Data&lt;/h2&gt;
&lt;p&gt;There are multiple version of AMR data, including:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;LDC2013E117:&lt;/strong&gt; 10,853 sentences with 13,050 AMRs (corpus includes multiple annotations for some sentences)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://catalog.ldc.upenn.edu/LDC2014T12&quot;&gt;LDC2014T12&lt;/a&gt; (AMR 1.0):&lt;/strong&gt; 13,051 sentences.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;LDC2015E86:&lt;/strong&gt; 19,572 sentences. This version includes more AMRs, wikification, AMR adoption of new unified PropBank frames, AMR deepening, automatic AMR-English alignments, and correction of AMR annotation errors.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;LDC2016E25:&lt;/strong&gt; 39,260 sentences.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://catalog.ldc.upenn.edu/LDC2017T10&quot;&gt;LDC2017T10&lt;/a&gt; (AMR 2.0):&lt;/strong&gt; 39,260 sentences.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiment--results&quot;&gt;Experiment &amp;amp; Results&lt;/h2&gt;

&lt;p&gt;These are the AMR parsing results on LDC2014T12, LDC2015E86 and LDC2017T10 test sets, where 2014N refers to the newswire section of LDC2014T12. You should look the original paper if you are interested in the model. &lt;strong&gt;Please contact me (through email) if the statistics is incorrect.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Paper&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Model&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;LDC2014N&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;LDC2014&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;LDC2015&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;LDC2017&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P18-1037&quot;&gt;ACL-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Lyu &amp;amp; Titov&lt;br /&gt;&lt;em&gt;University of Edinburgh &amp;amp; University of Amsterdam&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;73.7&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;74.4&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P18-1170&quot;&gt;ACL-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Groschwitz et al.&lt;br /&gt;&lt;em&gt;Saarland University &amp;amp; Macquerie University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;70.2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;71.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P17-1112.pdf&quot;&gt;ACL-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Buys &amp;amp; Blunsom&lt;br /&gt;&lt;em&gt;University of Oxford &amp;amp; Deepmind&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;61.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P17-1043&quot;&gt;ACL-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Foland &amp;amp; Martin&lt;br /&gt;&lt;em&gt;University of Colorado&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;70.7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D18-1198&quot;&gt;EMNLP-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Guo &amp;amp; Lu&lt;br /&gt;&lt;em&gt;Singapore University of Technology &amp;amp; Design&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;74.0&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;68.3&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;68.7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;69.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://arxiv.org/abs/1705.09980&quot;&gt;Arxiv-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;van Noord &amp;amp; Bos&lt;br /&gt;&lt;em&gt;University of Groningen&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;68.5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;71.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D17-1129&quot;&gt;EMNLP-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Wang &amp;amp; Xue&lt;br /&gt;&lt;em&gt;Brandeis University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;68.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;68.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/S16-1181&quot;&gt;Semeval-16&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Wang et al. (CAMR)&lt;br /&gt;&lt;em&gt;Brandeis University &amp;amp; Boulder Language Technologies&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;66.5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;67.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/S16-1176&quot;&gt;Semeval-16&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Barzdins &amp;amp; Gosko&lt;br /&gt;&lt;em&gt;University of Latvia&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;67.2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/S16-1186&quot;&gt;Semeval-16&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Flanigan et al. (JAMR)&lt;br /&gt;&lt;em&gt;Carnegie Mellon University &amp;amp; University of Washington&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;66&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;67&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/E17-1051&quot;&gt;EACL-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Damonte et al.&lt;br /&gt;&lt;em&gt;University of Edinburgh &amp;amp; University of Padua&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;64&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;64&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/N18-2023&quot;&gt;NAACL-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Vilares &amp;amp; Gómez-Rodríguez&lt;br /&gt;&lt;em&gt;Universidade da Coruña&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;64&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16563/16021&quot;&gt;AAAI-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Peng et al.&lt;br /&gt;&lt;em&gt;University of Rochester &amp;amp; University of Padua&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;64&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P17-1014&quot;&gt;ACL-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Konstas et al.&lt;br /&gt;&lt;em&gt;University of Washington &amp;amp; Allen Institute for Artificial Intelligence&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;62.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/E17-1035&quot;&gt;EACL-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Peng et al.&lt;br /&gt;&lt;em&gt;University of Rochester &amp;amp; Brandeis University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;52&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D15-1136&quot;&gt;EMNLP-15&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Pust et al.&lt;br /&gt;&lt;em&gt;Univerisity of Southern California&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;67.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D16-1065&quot;&gt;EMNLP-16&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Zhou et al.&lt;br /&gt;&lt;em&gt;Nianjin Normal University &amp;amp; DFKI, Germany&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;71&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;66&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/S16-1180&quot;&gt;Semeval-16&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Goodman et al.&lt;br /&gt;&lt;em&gt;University College London &amp;amp; University of Sheffeld&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;70&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;64&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P15-2141.pdf&quot;&gt;ACL-IJCNLP-15&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Wang et al. (CAMR)&lt;br /&gt;&lt;em&gt;Brandeis University &amp;amp; Boulder Language Technologies&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;70&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;66&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D17-1130&quot;&gt;EMNLP-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Ballesteros &amp;amp; AI-Onaizan&lt;br /&gt;&lt;em&gt;IBM T.J Waston Research Center&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;69&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;64&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D15-1198&quot;&gt;EMNLP-15&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Artzi et al.&lt;br /&gt;&lt;em&gt;Cornell University &amp;amp; University of Washington&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;67&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P15-1095&quot;&gt;ACL-IJCNLP-15&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Werling et al.&lt;br /&gt;&lt;em&gt;Stanford University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;62&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/N15-1040&quot;&gt;NAACL-15&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Wang et al. (CAMR)&lt;br /&gt;&lt;em&gt;Brandeis University &amp;amp; Harvard Medical School&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;59&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P14-1134&quot;&gt;ACL-14&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Flanigan et al. (JAMR)&lt;br /&gt;&lt;em&gt;Carnegie Mellon University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;59&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;58&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/K15-1004&quot;&gt;CoNLL-15&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Peng et al.&lt;br /&gt;&lt;em&gt;University of Rochester&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;58&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;semantic-dependency-parsing&quot;&gt;Semantic Dependency Parsing&lt;/h1&gt;

&lt;p&gt;Task 8 at SemEval 2014 defines &lt;em&gt;Broad-Coverage Semantic Dependency Parsing&lt;/em&gt; (SDP) as the problem of recovering sentence-internal predicate-argument relationships for &lt;em&gt;all content words&lt;/em&gt;, i.e., the semantic structure constituting the relational core of sentence meaning &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;SDP seeks to stimulate the dependency parsing community to move towards more general graph processing, to thus enable a more direct analysis of &lt;em&gt;Who did What to Whom?&lt;/em&gt; In addition to its relation to syntactic dependency parsing, the task also has some overlap with Semantic Role Labeling (SRL) &lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;The SDP parsers are required to identify all semantic dependencies, i.e., compute a representation that integrates all content words in one structure. Different from SRL, SDP task does not encompass predicate disambiguation, a design decision in part owed to SDP’s goal to focus on parsing-oriented, i.e., structural, analysis, and in part to lacking consensus on sense inventories for all content words.&lt;/p&gt;

&lt;p&gt;SDP uses three distinct target representations for semantic dependencies. Including:&lt;/p&gt;

&lt;h2 id=&quot;dm-delph-in-mrs-derived-bi-lexical-dependencies&quot;&gt;DM: DELPH-IN MRS-Derived Bi-Lexical Dependencies&lt;/h2&gt;

&lt;p&gt;These semantic dependency graphs originate in a manual re-annotation of Sections 00–21 of the WSJ Corpus with syntactico-semantic analyses derived from the LinGO English Resource Grammar (ERG) &lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;. The DM target representations are derived through a two-step ‘lossy’ conversion of MRSs, first to variable-free Elementary Dependency Structures (EDS) &lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;, then to ‘pure’ bi-lexical form - projecting some construction semantics onto word-to-word dependencies &lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;. For example, for the sentence “Ms. Haag plays Elianti.”, we have the DM representation as follows:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;id&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;form&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;lemma&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;pos&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;top&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;pred&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;arg1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;arg2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Ms.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Ms.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;NNP&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;+&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;_&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;_&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Haag&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Haag&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;NNP&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;compound&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;ARG1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;plays&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;play&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;VBZ&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;+&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;+&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;_&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;_&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Elianti&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Elianti&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;NNP&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;_&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;ARG2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;_&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;_&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;pas-enju-predicate-argument-structures&quot;&gt;PAS: Enju Predicate-Argument Structures&lt;/h2&gt;

&lt;p&gt;The Enju parsing system is an HPSG-based parser for English. The grammar and the disambiguation model of this parser are derived from the Enju HPSG treebank, which is automatically converted from the phrase structure and predicate-argument structure annotation of the PTB. The PAS data set is extracted from the WSJ portion of the Enju HPSG treebank. While the Enju treebank is annotated with full HPSG-style structures, only its predicate-argument structures are convert into the SDP data format for use in the SDP task.&lt;/p&gt;

&lt;h2 id=&quot;pcedt-prague-tectogrammatical-bi-lexical-dependencies&quot;&gt;PCEDT: Prague Tectogrammatical Bi-Lexical Dependencies&lt;/h2&gt;

&lt;p&gt;The Prague Czech-English Dependency TreeBank (PCEDT) &lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; is a set of parallel dependency trees over the WSJ texts from the PTB, and their Czech translations. The specifics of the PCEDT representations are best observed in the procedure that converts the original PCEDT data to the SDP data format; see Miyao et al. 2014 &lt;sup id=&quot;fnref:9&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h1 id=&quot;data-1&quot;&gt;Data&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://sdp.delph-in.net/2014/data.html&quot;&gt;Semeval-2014 Task 8&lt;/a&gt;:&lt;/strong&gt; For this task, there will be three data sets: training, development, and test.  On November 4, 2013, a sample (of some 190 dependency graphs) from the training data was published as &lt;a href=&quot;http://svn.delph-in.net/sdp/public/2014/trial/current.tgz&quot;&gt;trial data&lt;/a&gt;, demonstrating key characteristics of the task.  Since December 13, some 750,000 tokens of annotated text are available as training data; please subscribe to the task &lt;a href=&quot;http://lists.emmtee.net/mailman/listinfo/sdp-participants&quot;&gt;mailing list&lt;/a&gt; for access information.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://sdp.delph-in.net/2015/data.html&quot;&gt;Semeval-2015 Task 8&lt;/a&gt;:&lt;/strong&gt; This Task is a re-run with some extensions of Task 8 at SemEval-2014.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;experiment--results-1&quot;&gt;Experiment &amp;amp; Results&lt;/h1&gt;

&lt;p&gt;The results are the labeled parsing performance (F1 score) on both in-domain and out-of-domain test data and are based on the English dataset from SemEval 2015 Task 18 closed track. The data split is 33,964 training sentences from 00-19 of the WSJ corpus, 1,692 development sentences from 20, 1,410 sentences from 21 as in domain test data, and 1,849 sentences sampled from the Brown Corpus as out-of-domain test data.&lt;/p&gt;

&lt;h2 id=&quot;in-domain&quot;&gt;In-Domain&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;paper&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;model&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;DM&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;PAS&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;PSD&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P18-2077&quot;&gt;ACL-2018&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Dozat &amp;amp; Manning&lt;br /&gt;&lt;em&gt;Stanford University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;93.7&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;93.9&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;81.0&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P17-1186&quot;&gt;ACL-2017&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Peng et al.&lt;br /&gt;&lt;em&gt;University of Washington &amp;amp; Carnegie Mellon University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;90.4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;92.7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;78.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16549/16113&quot;&gt;AAAI-2018&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Wang et al.&lt;br /&gt;&lt;em&gt;Harbin Institute of Technology&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;90.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;91.7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;78.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/S15-2154&quot;&gt;Semeval-2015&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Du et al.&lt;br /&gt;&lt;em&gt;Peking University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;89.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;91.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;75.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/S15-2162&quot;&gt;Semeval-2015&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Almeida &amp;amp; Martins&lt;br /&gt;&lt;em&gt;Priberam Labs &amp;amp; Instituto de Telecomunicacoes&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;88.2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;90.9&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;76.4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;out-of-domain&quot;&gt;Out-Of-Domain&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;paper&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;model&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;DM&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;PAS&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;PSD&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P18-2077&quot;&gt;ACL-2018&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Dozat &amp;amp; Manning&lt;br /&gt;&lt;em&gt;Stanford University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;88.9&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;90.6&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;79.4&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P17-1186&quot;&gt;ACL-2017&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Peng et al.&lt;br /&gt;&lt;em&gt;University of Washington &amp;amp; Carnegie Mellon University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;89.0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;76.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16549/16113&quot;&gt;AAAI-2018&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Wang et al.&lt;br /&gt;&lt;em&gt;Harbin Institute of Technology&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;84.9&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;87.6&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;75.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/S15-2154&quot;&gt;Semeval-2015&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Du et al.&lt;br /&gt;&lt;em&gt;Peking University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;81.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;87.2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;73.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/S15-2162&quot;&gt;Semeval-2015&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Almeida &amp;amp; Martins&lt;br /&gt;&lt;em&gt;Priberam Labs &amp;amp; Instituto de Telecomunicacoes&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;81.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;86.9&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;74.8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;logical-form-representation&quot;&gt;Logical Form Representation&lt;/h1&gt;
&lt;p&gt;First-order logic is used as a semantic representation language (MRL), which is designed by the creator of the application to suit the application’s need independent of natural language. Some MRL data sets are based on Prolog database, where two well-known semantic parsing benchmark data sets are Jobs and Geo &lt;sup id=&quot;fnref:10&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Here we explain the features of the Geoquery representation language through a sample query:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input: &quot;What is the largest city in Texas?&quot;
Query: answer(C, largest(C, (city(C), loc(C, S), const(S, stateid(texas)))))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Objects are represented as logical terms and are typed with a semantic category using logical functions applied to possibly ambiguous English constants (e.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;stateid(Mississippi), riverid(Mississippi)&lt;/code&gt;). Relationships between objects are expressed using predicates; for instance, &lt;code class=&quot;highlighter-rouge&quot;&gt;loc(X, Y)&lt;/code&gt; states that &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; is located in &lt;code class=&quot;highlighter-rouge&quot;&gt;Y&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We also need to handle quantifiers such as ‘largest’. We represent these using &lt;em&gt;meta-predicates&lt;/em&gt; for which at least one argument is a conjunction of literals. For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;largest(X, Goal)&lt;/code&gt; states that the object &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; satisfies &lt;code class=&quot;highlighter-rouge&quot;&gt;Goal&lt;/code&gt; and is the largest object that does so, using the appropriate measure of size for objects of its type (e.g. area for states, population for cities). Finally, an unspecified object required as an argument to a predicate can appear elsewhere in the sentence, requiring the use of the predicate &lt;code class=&quot;highlighter-rouge&quot;&gt;const(X, C)&lt;/code&gt; to bind the variable &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; to the constant &lt;code class=&quot;highlighter-rouge&quot;&gt;C&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;data-2&quot;&gt;Data&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/zi-lin/zi-lin.github.io/tree/master/data/geo880&quot;&gt;Geo 880&lt;/a&gt;:&lt;/strong&gt;  A set of 880 queries to a database of U.S. geography containing basic information about the U.S. states like population, area, capital city, neighboring states, and so on. It is originally annotated with Prolog style semantics. Geo has 880 instances split into a training set of 680 training examples and 200 test examples &lt;sup id=&quot;fnref:11&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/zi-lin/zi-lin.github.io/tree/master/data/jobs640&quot;&gt;Jobs 640&lt;/a&gt;:&lt;/strong&gt; A set of 640 queries to a database of computer-related job postings, such as job announcements, from the USENET newsgroup &lt;code class=&quot;highlighter-rouge&quot;&gt;austin.jobs&lt;/code&gt;. Information from these job postings are extracted to create a database which contains the following types of information: 1) the job title, 2) the company, 3) the recruiter, 4) the location, 5) the salary, 6) the languages and platforms used, and 7) required or desired years of experience and degrees. The training-test split contains 500 training and 140 test instances.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.kaggle.com/siddhadev/ms-cntk-atis&quot;&gt;ATIS&lt;/a&gt;:&lt;/strong&gt;  A set of 5,410 queries to a flight booking system, and the representations are of lambda-calculus logical forms. The ATIS database consists of data obtained from the Official Airline Guide (OAG, 1990), organized under a relational schema. The database remained fixed throughout the pilot phase. It contains information about flights, fares, airlines, cities, airports, and ground services, and includes twenty-five supporting tables. The large majority of the questions posed by subjects can be answered from the database with a single relational query.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiment--results-2&quot;&gt;Experiment &amp;amp; Results&lt;/h2&gt;
&lt;p&gt;The results are based on accuracies which are defined as the proportion of the input sentences that are correctly parsed to their gold standard logical forms.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;paper&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;model&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Geo880&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Jobs640&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ATIS&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D18-1110&quot;&gt;EMNLP-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Xu et al.&lt;br /&gt;&lt;em&gt;Tencent AI Lab &amp;amp; IBM Research &amp;amp; Peking University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;88.1&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;91.2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;85.9&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P17-1105&quot;&gt;ACL-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Rabinovich et al.&lt;br /&gt;&lt;em&gt;UC Berkeley&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85.7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;92.9&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P11-1060&quot;&gt;ACL-11&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Liang et al.&lt;br /&gt;&lt;em&gt;UC Berkeley&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;87.9&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;90.7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D14-1135&quot;&gt;ACL-14&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Wang et al.&lt;br /&gt;&lt;em&gt;University of Washington &amp;amp; Allen Institute for AI&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;90.4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;91.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D13-1161&quot;&gt;EMNLP-13&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Kwiatkowski et al.&lt;br /&gt;&lt;em&gt;University of Washington&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;89.0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/N15-1162&quot;&gt;NAACL-15&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Zhao and Huang&lt;br /&gt;&lt;em&gt;City University of New York&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;88.9&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85.0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;84.2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P13-1092&quot;&gt;ACL-13&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Poon&lt;br /&gt;Microsoft Research&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;83.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D11-1140&quot;&gt;EMNLP-11&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Kwiatkowski et al.&lt;br /&gt;&lt;em&gt;University of Edinburgh &amp;amp; University of Washington&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;88.6&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;82.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D10-1119&quot;&gt;EMNLP-10&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Kwiatkowski et al.&lt;br /&gt;&lt;em&gt;University of Edinburgh &amp;amp; University of Washington&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;87.9&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;71.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P16-1004&quot;&gt;ACL-16&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Dong &amp;amp; Lapata -Seq2Tree&lt;br /&gt;&lt;em&gt;University of Edinburgh&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;87.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;90.0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P07-1121&quot;&gt;ACL-07&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Wong and Mooney&lt;br /&gt;&lt;em&gt;University of Texas&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;86.6&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D07-1071&quot;&gt;EMNLP-CoNLL-07&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Zettlemoyer and Collins&lt;br /&gt;&lt;em&gt;MIT&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;86.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;84.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P16-1004&quot;&gt;ACL-16&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Dong &amp;amp; Lapata -Seq2Seq&lt;br /&gt;&lt;em&gt;University of Edinburgh&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85.0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;87.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;84.2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P16-1002&quot;&gt;ACL-16&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Jia &amp;amp; Liang&lt;br /&gt;&lt;em&gt;Stanford University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85.0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;76.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/D08-1082&quot;&gt;EMNLP-08&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Lu et al.&lt;br /&gt;&lt;em&gt;Singapore-MIT alliance &amp;amp; National University of Singapore &amp;amp; MIT&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;81.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://link.springer.com/content/pdf/10.1007%2F3-540-44795-4_40.pdf&quot;&gt;ECML-01&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Tang &amp;amp; Mooney&lt;br /&gt;&lt;em&gt;University of Texas&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;79.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;79.4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://arxiv.org/ftp/arxiv/papers/1207/1207.1420.pdf&quot;&gt;UAI-05&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Zettlemoyer and Collins&lt;br /&gt;&lt;em&gt;MIT&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;79.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;79.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://turing.cs.washington.edu/papers/nli-iui03.pdf&quot;&gt;IUI-03&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Poposcu et al.&lt;br /&gt;&lt;em&gt;University of Washington&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;77.5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;88.0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/N06-1056&quot;&gt;NAACL-06&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Wong and Mooney&lt;br /&gt;&lt;em&gt;University of Texas&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;74.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=1706546&quot;&gt;CoNLL-05&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Ge and Mooney&lt;br /&gt;&lt;em&gt;University of Texas&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;72.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P06-1115&quot;&gt;COLING-ACL-06&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Kate and Mooney&lt;br /&gt;&lt;em&gt;University of Texas&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;71.7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;sql-query&quot;&gt;SQL Query&lt;/h1&gt;
&lt;p&gt;In recent years, there has been considerable interest in automated synthesis of programs from informal specifications. A particularly promising application domain for such computer-aided programming techniques is the automated synthesis of database queries. Although many end-users need to query data stored in some relational database, they typically lack the expertise to write complex queries in declarative query languages such as SQL. As a result, there has been a flurry of interest in automatically synthesizing SQL queries from informal specifications. Here we will talk about the techniques that can generate SQL queries from natural language (NL) descriptions.&lt;/p&gt;

&lt;p&gt;For example, for the sentence “how many CFL teams are from York College”, we will have the SRL query like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SELECT COUNT CFL Team FROM
CFLDraft WHERE College = &quot;York&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;data-3&quot;&gt;Data&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/salesforce/WikiSQL&quot;&gt;WikiSQL&lt;/a&gt;:&lt;/strong&gt; WikiSQL is a collection of questions, corresponding SQL queries, and SQL tables. It is the largest hand-annotated semantic parsing dataset to data - it is an order of magnitude larger than other datasets that have logical forms, either in terms of the number of examples or the number of tables. The corpus consists of 80654 hand-annotated instances of natural language questions, SQL queries, and SQL tables extracted from 24241 HTML tables from Wikipedia &lt;sup id=&quot;fnref:12&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiment-and-results&quot;&gt;Experiment and Results&lt;/h2&gt;
&lt;p&gt;To learn more about the experiment and results on WikiSQL, see &lt;a href=&quot;https://github.com/salesforce/WikiSQL&quot;&gt;https://github.com/salesforce/WikiSQL&lt;/a&gt; for more details.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Rohit J Kate and YukWahWong. 2010. Semantic parsing: The task, the state of the art and the future. Tutorial Abstracts of ACL 2010 page 6. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider. 2013. Abstract meaning representation for SemBanking. In Proc. of the 7th Linguistic Annotation Workshop and Interoperability with Discourse. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;Oepen, S., Kuhlmann, M., Miyao, Y., Zeman, D., Flickinger, D., Hajic, J., Ivanova, Angelina, Zhang, Y. 2014. SemEval 2014 Task 8: Broad-coverage semantic dependency parsing. In Proceedings of the 8th International Workshop on Semantic Evaluation. Dublin, Ireland. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Gildea, D., &amp;amp; Jurafsky, D. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28, 71:245–288. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;Flickinger, D., Zhang, Y., &amp;amp; Kordoni, V. 2012. DeepBank. A dynamically annotated treebank of the Wall Street Journal. In Proceedings of the 11th International Workshop on Treebanks and Linguistic Theories (p. 85–96). Lisbon, Portugal: Edições Colibri. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;Oepen, S., &amp;amp; Lønning, J. T. 2006. Discriminantbased MRS banking. In Proceedings of the 5th International Conference on Language Resources and Evaluation (p. 1250–1255). Genoa, Italy. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;Ivanova, A., Oepen, S., Øvrelid, L., &amp;amp; Flickinger, D. 2012. Who did what to whom? A contrastive study of syntacto-semantic dependencies. In Proceedings of the Sixth Linguistic Annotation Workshop (p. 2–11). Jeju, Republic of Korea. &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;Hajic, J., Hajicová, E., Panevová, J., Sgall, P., Bojar, O., Cinková, S., … &amp;amp; Semecký, J. 2012. Announcing Prague Czech-English Dependency Treebank 2.0. In LREC (pp. 3153-3160). &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot;&gt;
      &lt;p&gt;Miyao, Y., Oepen, S., &amp;amp; Zeman, D. 2014. In-house: An ensemble of pre-existing off-the-shelf parsers. In Proceedings of the 8th International Workshop on Semantic Evaluation. Dublin, Ireland. &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot;&gt;
      &lt;p&gt;Lappoon R. Tang and Raymond J. Mooney. 2001. Using multiple clause constructors in inductive logic programming for semantic parsing. In Proceedings of the 12th ECML, pages 466–477, Freiburg, Germany. &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot;&gt;
      &lt;p&gt;Luke S. Zettlemoyer and Michael Collins. 2005. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proceedings of the 21st UAI, pages 658–666, Toronto, ON. &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot;&gt;
      &lt;p&gt;Zhong, V., Xiong, C. and Socher, R., 2017. Seq2SQL: Generating structured queries from natural language using reinforcement learning. arXiv preprint arXiv:1709.00103. &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Zi Lin</name></author><category term="NLP Tasks" /><summary type="html">Introduction In fact, “semantic parsing” is, ironically, a semantically ambiguous term, which could refer to:</summary></entry><entry><title type="html">Semantic Role Labeling</title><link href="http://localhost:4000/SRL/" rel="alternate" type="text/html" title="Semantic Role Labeling" /><published>2018-11-10T00:00:00+08:00</published><updated>2018-11-10T00:00:00+08:00</updated><id>http://localhost:4000/SRL</id><content type="html" xml:base="http://localhost:4000/SRL/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Semantic Role Labeling (SRL)&lt;/strong&gt;, sometimes called &lt;em&gt;shallow semantic parsing&lt;/em&gt;, is a process in natural language processing that assigns semantic roles to constituents or their head words in a sentence according to their relationship to the predicates expressed in the sentence. Typical semantic roles can be divided into core &lt;strong&gt;arguments&lt;/strong&gt; and &lt;strong&gt;adjuncts&lt;/strong&gt;. The core arguments include &lt;em&gt;Agent, Patient, Source, Goal&lt;/em&gt;, etc, While the adjuncts include &lt;em&gt;Location, Time, Manner, Cause&lt;/em&gt;, etc.&lt;/p&gt;

&lt;p&gt;For example, in the sentence &lt;code class=&quot;highlighter-rouge&quot;&gt;I ate breakfast quickly in the car this morning because I was in a hurry&lt;/code&gt;, we can have the labeled sentence like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[I]&lt;sub&gt;agent&lt;/sub&gt; [&lt;strong&gt;eat&lt;/strong&gt;]&lt;sub&gt;predicate&lt;/sub&gt; [breakfast]&lt;sub&gt;patient&lt;/sub&gt; [quickly]&lt;sub&gt;manner&lt;/sub&gt; [in the car]&lt;sub&gt;location&lt;/sub&gt; [this morning]&lt;sub&gt;time&lt;/sub&gt; [because I was in a hurry]&lt;sub&gt;cause&lt;/sub&gt; .&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;source&quot;&gt;Source&lt;/h1&gt;
&lt;p&gt;There are mainly three sources for SRL, namely, &lt;a href=&quot;https://propbank.github.io/&quot;&gt;PropBank&lt;/a&gt;, &lt;a href=&quot;https://framenet.icsi.berkeley.edu/fndrupal/&quot;&gt;FrameNet&lt;/a&gt; and &lt;a href=&quot;https://verbs.colorado.edu/~mpalmer/projects/verbnet.html&quot;&gt;VerbNet&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;propbank&quot;&gt;PropBank&lt;/h2&gt;
&lt;p&gt;PropBank is a corpus in which the arguments of each predicate are annotated with their semantic roles in relation to the predicate &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Currently, all the PropBank annotations are done on top of the phrase structure annotation of the &lt;strong&gt;Pen TreeBank&lt;/strong&gt; &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. In addition to semantic role annotation, PropBank annotation requires the choice of a sense ID (also known as &lt;em&gt;frameset&lt;/em&gt; or &lt;em&gt;roleset&lt;/em&gt; ID) for each predicate. Thus, for each verb in every tree (representing the phrase structure of the corresponding sentence), PropBank has the instance that consists of the sense ID of the predicate (e.g. eat.01) and its arguments labeled with semantic roles.&lt;/p&gt;

&lt;p&gt;An important goal is to provide consistent argument labels across different syntactic realizations of the same verb, as in…&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[I]&lt;sub&gt;ARG0&lt;/sub&gt; [&lt;strong&gt;eat&lt;/strong&gt;]&lt;sub&gt;predicate&lt;/sub&gt; [breakfast]&lt;sub&gt;ARG1&lt;/sub&gt; [quickly]&lt;sub&gt;ARGM-MNR&lt;/sub&gt; [in the car]&lt;sub&gt;ARGM-LOC&lt;/sub&gt; [this morning]&lt;sub&gt;ARGM-TMP&lt;/sub&gt; [because I was in a hurry]&lt;sub&gt;ARGM-CAU&lt;/sub&gt; .&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The argument structure of each predicate is outlined in the PropBank frame file for that predicate. The frame file denotes the correspondences between numbered arguments and semantic roles, as this is somewhat unique for each predicate.&lt;/p&gt;

&lt;p&gt;Numbered arguments reflect either the arguments that are required for the valency of a predicate (e.g., agent, patient, benefactive), or if not required, those that occur with high-frequency in actual usage. Although numbered arguments correspond to slightly different semantic roles given the usage of each predicate, in general numbered arguments correspond to the following semantic roles:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;ARG0&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;agent&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;ARG3&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;starting point, benefactive, attribute&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;ARG1&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;patient&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;ARG4&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;ending point&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;ARG2&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;instrument, benefactive, attribute&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;ARGM&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;modifier&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;framenet&quot;&gt;FrameNet&lt;/h2&gt;
&lt;p&gt;The FrameNet project is to design a lexical database of English based on a linguistic theory called &lt;strong&gt;Frame Semantics&lt;/strong&gt;. The meaning of most words can best be understood on the basis of a semantic frame, and the basic assumption on which the frames are built is that each word evokes a particular situation with particular participants&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;For example, the concept of &lt;em&gt;eat&lt;/em&gt; usually involves a person doing the eating (&lt;code class=&quot;highlighter-rouge&quot;&gt;Ingester&lt;/code&gt;), the food that is to be eaten (&lt;code class=&quot;highlighter-rouge&quot;&gt;Ingestibles&lt;/code&gt;). In FrameNet, this event is represented as a frame called &lt;code class=&quot;highlighter-rouge&quot;&gt;Ingestion&lt;/code&gt;, while the &lt;code class=&quot;highlighter-rouge&quot;&gt;Ingester&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Ingestibles&lt;/code&gt; are all frame elements (FEs), and predicates &lt;em&gt;eat&lt;/em&gt; evoking frames are called lexical unites (LUs). One frame can have multiple lexical unites, e.g., for the frame &lt;code class=&quot;highlighter-rouge&quot;&gt;Ingestion&lt;/code&gt;, we can have &lt;em&gt;consume, devour, drink, eat, feed&lt;/em&gt;, etc.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[I]&lt;sub&gt;Ingester&lt;/sub&gt; [&lt;strong&gt;eat&lt;/strong&gt;]&lt;sub&gt;LUs&lt;/sub&gt; [breakfast]&lt;sub&gt;Ingestibles&lt;/sub&gt; [quickly]&lt;sub&gt;Manner&lt;/sub&gt; [in the car]&lt;sub&gt;Place&lt;/sub&gt; [this morning]&lt;sub&gt;Time&lt;/sub&gt; because I was in a hurry.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;verbnet&quot;&gt;VerbNet&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;[I]&lt;sub&gt;Agent&lt;/sub&gt; [&lt;strong&gt;eat&lt;/strong&gt;]&lt;sub&gt;Verb&lt;/sub&gt; [breakfast]&lt;sub&gt;Patient&lt;/sub&gt; quickly in the car this morning because I was in a hurry.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;data&quot;&gt;Data&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://www.lsi.upc.edu/~srlconll/conll05st-release.tar.gz&quot;&gt;CoNLL-2005&lt;/a&gt;:&lt;/strong&gt; The CoNLL-2005 dataset takes section 2-21 of the Wall Street Journal (WSJ) corpus as training set, and section 24 as development set. The test set consist of section 23 of the &lt;strong&gt;WSJ&lt;/strong&gt; corpus (in-domain test) as well as 3 section from the &lt;strong&gt;Brown&lt;/strong&gt; corpus (out-of-domain test) &lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://conll.cemantix.org/2012/data.html&quot;&gt;CoNLL-2012&lt;/a&gt;:&lt;/strong&gt; The CoNLL-2012 dataset is extracted from the OntoNotes v5.0 corpus &lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;. The description and separation of training, development and test set can be found in &lt;a href=&quot;http://www.aclweb.org/anthology/W13-3516&quot;&gt;Pardhan et al. (2013)&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;experiments--results&quot;&gt;Experiments &amp;amp; Results&lt;/h1&gt;

&lt;p&gt;Note: All the statistics are obtained from the exact papers or papers citing the exact papers. Contact me if the statistics are not correct or you think your model should be listed as one of them.&lt;/p&gt;

&lt;h2 id=&quot;with-gold-predicate&quot;&gt;With Gold Predicate&lt;/h2&gt;

&lt;p&gt;Of course, for each model, we can have different versions, e.g., using the word embeddings from Glove or ELMo, and different versions can lead to different results. Here I just list the results for one of the versions, most of which are single models without using any tricks. I will specify if there are tricks leveraged, e.g., LISA+&lt;strong&gt;D&amp;amp;M&lt;/strong&gt;. You should look the original paper if you are interested in the model, and check whether there are some other versions of the model yielding better results. &lt;strong&gt;Please contact me (through email) if the statistics is incorrect.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Paper&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Model&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;WSJ&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Brown&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;CoNLL-2012&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D18-1548&quot;&gt;EMNLP-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;LISA+D&amp;amp;M&lt;br /&gt;&lt;em&gt;University of Massachusetts Amherst &amp;amp; Google AI Language&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;86.04&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;76.54&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/N18-1202&quot;&gt;NAACL-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Peter et al.+ELMo&lt;br /&gt;&lt;em&gt;Allen Institute for Artificial Intelligence &amp;amp; University of Washington&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;84.6&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16725/16025&quot;&gt;AAAI-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Tan et al.&lt;br /&gt;&lt;em&gt;Xiamen University &amp;amp; Tencent Technology Co.&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;84.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;74.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;82.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P18-2058&quot;&gt;ACL-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;He et al.&lt;br /&gt;&lt;em&gt;University of Washington&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;83.9&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;73.7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;82.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P17-1044&quot;&gt;ACL-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;He et al.&lt;br /&gt;&lt;em&gt;University of Washington, Facebook AI Research &amp;amp; Allen Institute for Artificial Intelligence&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;83.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;72.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;81.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D17-1128&quot;&gt;EMNLP-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Yang and Mitchell&lt;br /&gt;&lt;em&gt;Carnegie Mellon University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;81.9&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;72.0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/P15-1109&quot;&gt;ACL-15&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Zhou and Xu&lt;br /&gt;&lt;em&gt;Baidu Research&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;82.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;69.4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;81.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D15-1112&quot;&gt;EMNLP-15&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;FitzGerald at al.&lt;br /&gt;&lt;em&gt;University of Washington &amp;amp; Google&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;80.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;72.2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;80.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/Q15-1003&quot;&gt;TACL-15&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Tackstrom et al.&lt;br /&gt;&lt;em&gt;Google&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;79.9&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;71.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;79.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/W13-3516&quot;&gt;CoNLL-13&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Pradhan et al.&lt;br /&gt;&lt;em&gt;Boston Children’s Hospital and Harvard Medical School, University of Trento, QCRI, Brandeis University, National University of Singapore &amp;amp; University of Stuttgart&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;77.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/J/J08/J08-2002.pdf&quot;&gt;CL-08&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Toutanova et al.&lt;br /&gt;&lt;em&gt;Microsoft Research, University of California Berkeley &amp;amp; Stanford University&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;80.3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;68.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://www.mitpressjournals.org/doi/pdf/10.1162/coli.2008.34.2.257&quot;&gt;CL-08&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Punyakanok et al.&lt;br /&gt;&lt;em&gt;BBN Technologies, University of Illinois at Urbana-Champaign &amp;amp; Microsoft Research&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;79.4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;67.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;without-gold-predicate&quot;&gt;Without Gold Predicate&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Paper&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Model&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;WSJ&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Brown&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;CoNLL-2012&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D18-1548&quot;&gt;EMNLP-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;LISA+ELMo+D&amp;amp;M&lt;br /&gt;&lt;em&gt;University of Massachusetts Amherst &amp;amp; Google AI Language&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;86.90&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;78.25&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;83.38&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P18-2058&quot;&gt;ACL-18&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;He et al.+ELMo&lt;br /&gt;&lt;em&gt;University of Washington&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;86.0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;76.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;82.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/P17-1044&quot;&gt;ACL-17&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;He et al.+GloVe+PoE&lt;br /&gt;&lt;em&gt;University of Washington, Facebook AI Research &amp;amp; Allen Institute for Artificial Intelligence&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;82.7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;70.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;78.4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71-106. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: the penn treebank. Computational Linguistics, 19(2):313-330. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;Charles J Fillmore. 1968. The Case for Case. Universals in Linguistic Theory. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Xavier Carreras and Lluis Marquez. 2005. Introduction to the conll-2005 shared task: Semantic role labeling. In CoNLL. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Hwee Tou Ng, Anders Bjorkelund, Olga Uryupina, Yuchen Zhang, and Zhi Zhong. 2013. Towards robust linguistic analysis using ontonotes. In CoNLL. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Zi Lin</name></author><category term="NLP Tasks" /><summary type="html">Introduction Semantic Role Labeling (SRL), sometimes called shallow semantic parsing, is a process in natural language processing that assigns semantic roles to constituents or their head words in a sentence according to their relationship to the predicates expressed in the sentence. Typical semantic roles can be divided into core arguments and adjuncts. The core arguments include Agent, Patient, Source, Goal, etc, While the adjuncts include Location, Time, Manner, Cause, etc.</summary></entry><entry><title type="html">Brief Introduction to Abstract Meaning Representation</title><link href="http://localhost:4000/intro-amr/" rel="alternate" type="text/html" title="Brief Introduction to Abstract Meaning Representation" /><published>2018-04-13T00:00:00+08:00</published><updated>2018-04-13T00:00:00+08:00</updated><id>http://localhost:4000/intro-amr</id><content type="html" xml:base="http://localhost:4000/intro-amr/">&lt;p&gt;&lt;strong&gt;AMR (Abstract Meaning Representation)&lt;/strong&gt;, is a set of sentences paired with simple, readable semantic representations. Remember that we have talked about FrameNet, a well-known ontology for frame semantic representations. If you want to know more about AMR, click &lt;a href=&quot;http://zi-lin.com/pdf/intro-AMR_zilin.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>Zi Lin</name><email>linzi.pku@gmail.com</email></author><category term="Meaning Representation" /><summary type="html">AMR (Abstract Meaning Representation), is a set of sentences paired with simple, readable semantic representations. Remember that we have talked about FrameNet, a well-known ontology for frame semantic representations. If you want to know more about AMR, click here.</summary></entry><entry><title type="html">Brief Introduction to Ontologies</title><link href="http://localhost:4000/intro-ontology/" rel="alternate" type="text/html" title="Brief Introduction to Ontologies" /><published>2017-09-21T00:00:00+08:00</published><updated>2017-09-21T00:00:00+08:00</updated><id>http://localhost:4000/intro-ontology</id><content type="html" xml:base="http://localhost:4000/intro-ontology/">&lt;p&gt;Have you ever heard of WordNet, HowNet, FrameNet and ConceptNet? There are different kinds of ontologies towards lexicon, syntax and commonsense knowledge.&lt;/p&gt;

&lt;p&gt;I have made a slides helping you to learn something about them, click &lt;a href=&quot;http://zi-lin.com/pdf/intro-ontologies.pdf&quot;&gt;here&lt;/a&gt; if you are interested!&lt;/p&gt;</content><author><name>Zi Lin</name><email>linzi.pku@gmail.com</email></author><category term="Meaning Representation" /><summary type="html">Have you ever heard of WordNet, HowNet, FrameNet and ConceptNet? There are different kinds of ontologies towards lexicon, syntax and commonsense knowledge.</summary></entry><entry><title type="html">Build a Simple C Compiler with a Parse Tree!</title><link href="http://localhost:4000/build-c-compiler/" rel="alternate" type="text/html" title="Build a Simple C Compiler with a Parse Tree!" /><published>2017-06-01T00:00:00+08:00</published><updated>2017-06-01T00:00:00+08:00</updated><id>http://localhost:4000/build-c-compiler</id><content type="html" xml:base="http://localhost:4000/build-c-compiler/">&lt;p&gt;Hi, there! I has completed my assignment for the course called Principles of Compilers eventually - building a simple C compiler. Additionally, I also wrote a Python draft to visualize the parse tree :) For more information about the process, please click &lt;a href=&quot;http://zi-lin.com/pdf/assignment_report.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>Zi Lin</name><email>linzi.pku@gmail.com</email></author><category term="Coursework" /><summary type="html">Hi, there! I has completed my assignment for the course called Principles of Compilers eventually - building a simple C compiler. Additionally, I also wrote a Python draft to visualize the parse tree :) For more information about the process, please click here.</summary></entry><entry><title type="html">Brief Introduction to Chinese Morphology</title><link href="http://localhost:4000/chinese-morphology/" rel="alternate" type="text/html" title="Brief Introduction to Chinese Morphology" /><published>2017-03-06T00:00:00+08:00</published><updated>2017-03-06T00:00:00+08:00</updated><id>http://localhost:4000/chinese-morphology</id><content type="html" xml:base="http://localhost:4000/chinese-morphology/">&lt;p&gt;This is the draft I wrote for my presentation for the course called &lt;strong&gt;English Lexicoiogy&lt;/strong&gt;, where I was asked to introduce something about Chinese morphology to student from College of Foreign Languages.&lt;/p&gt;

&lt;p&gt;Chinese morphology, or rather, Chinese word-formation is quite different from English for it has less derivation. Also, parataxis plays a vital role in the process of word building. You can click &lt;a href=&quot;http://zi-lin.com/pdf/introduction-chinese-morphology.pdf&quot;&gt;here&lt;/a&gt; to get access to my draft.&lt;/p&gt;</content><author><name>Zi Lin</name><email>linzi.pku@gmail.com</email></author><category term="Linguistics" /><summary type="html">This is the draft I wrote for my presentation for the course called English Lexicoiogy, where I was asked to introduce something about Chinese morphology to student from College of Foreign Languages.</summary></entry></feed>